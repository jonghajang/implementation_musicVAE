{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9abd6046-077a-4a7b-950a-dad4ddcd1cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import pandas as pd\n",
    "import random\n",
    "from magenta.common import merge_hparams\n",
    "from magenta.contrib import training as contrib_training\n",
    "from magenta.models.music_vae import MusicVAE, lstm_models, configs\n",
    "from magenta.models.music_vae import data\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "import magenta.music as mm\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim \n",
    "import note_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5732e340-ab09-4313-aa89-31274d50c59a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddd9e700-6a53-4c0d-ae79-3114642958fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config(collections.namedtuple('Config',\n",
    "                                    ['model', 'hparams', 'note_sequence_augmenter', 'data_converter',\n",
    "                                     'train_examples_path', 'eval_examples_path', 'tfds_name'])):\n",
    "    def values(self):\n",
    "        return self._asdict()\n",
    "\n",
    "Config.__new__.__defaults__ = (None,) * len(Config._fields)\n",
    "\n",
    "def update_config(config, update_dict):\n",
    "    config_dict = config.values()\n",
    "    config_dict.update(update_dict)\n",
    "    return Config(**config_dict)\n",
    "\n",
    "HParams = contrib_training.HParams\n",
    "\n",
    "CONFIG_MAP = {}\n",
    "CONFIG_MAP['groovae_4bar'] = Config(\n",
    "    model=MusicVAE(lstm_models.BidirectionalLstmEncoder(),\n",
    "                   lstm_models.GrooveLstmDecoder()),\n",
    "    hparams=merge_hparams(\n",
    "        lstm_models.get_default_hparams(),\n",
    "        HParams(\n",
    "            batch_size=512,\n",
    "            max_seq_len=16 * 4,  # 4 bars w/ 16 steps per bar\n",
    "            z_size=256,\n",
    "            enc_rnn_size=[512],\n",
    "            dec_rnn_size=[256, 256],\n",
    "            max_beta=0.2,\n",
    "            free_bits=48,\n",
    "            dropout_keep_prob=0.3,\n",
    "        )),\n",
    "    note_sequence_augmenter=None,\n",
    "    data_converter=data.GrooveConverter(\n",
    "        split_bars=4, steps_per_quarter=4, quarters_per_bar=4,\n",
    "        max_tensors_per_notesequence=20,\n",
    "        pitch_classes=data.ROLAND_DRUM_PITCH_CLASSES,\n",
    "        inference_pitch_classes=data.REDUCED_DRUM_PITCH_CLASSES),\n",
    "    # change to custom data\n",
    "    train_examples_path='./data/groovae_4bar.tfrecord-00000-of-00001',\n",
    "    eval_examples_path='./data/groove_eval/eval_music.tfrecord'\n",
    ")\n",
    "\n",
    "CONFIG_MAP['cat-drums_2bar_big'] = Config(\n",
    "    model=MusicVAE(lstm_models.BidirectionalLstmEncoder(),\n",
    "                   lstm_models.CategoricalLstmDecoder()),\n",
    "    hparams=merge_hparams(\n",
    "        lstm_models.get_default_hparams(),\n",
    "        HParams(\n",
    "            batch_size=512,\n",
    "            max_seq_len=64,  # 원래 2bars를 4bars로 변환했습니다. 4 bars w/ 16 steps per bar\n",
    "            z_size=512,\n",
    "            enc_rnn_size=[2048],\n",
    "            dec_rnn_size=[2048, 2048, 2048],\n",
    "            free_bits=48,\n",
    "            max_beta=0.2,\n",
    "            sampling_schedule='inverse_sigmoid',\n",
    "            sampling_rate=1000,\n",
    "        )),\n",
    "    note_sequence_augmenter=None,\n",
    "    data_converter=data.DrumsConverter(\n",
    "        # max_bars=100,  # 앞서 pre-processing 과정을 거쳤기 때문에 주석처리\n",
    "        slice_bars=4,\n",
    "        steps_per_quarter=4,\n",
    "        roll_input=False),\n",
    "    # change to custom data\n",
    "    train_examples_path='./data/groovae_4bar.tfrecord-00000-of-00001',\n",
    "    eval_examples_path='./data/groove_eval/eval_music.tfrecord',\n",
    ")\n",
    "\n",
    "CONFIG_MAP['groovae_4bar_hier'] = Config(\n",
    "    model=MusicVAE(lstm_models.BidirectionalLstmEncoder(),\n",
    "                   lstm_models.HierarchicalLstmDecoder(\n",
    "                       lstm_models.GrooveLstmDecoder(),\n",
    "                       level_lengths=[16, 4])),\n",
    "    hparams=merge_hparams(\n",
    "        lstm_models.get_default_hparams(),\n",
    "        HParams(\n",
    "            batch_size=512,\n",
    "            max_seq_len=16 * 4,  # 4 bars w/ 16 steps per bar\n",
    "            z_size=256,\n",
    "            enc_rnn_size=[512],\n",
    "            dec_rnn_size=[256, 256],\n",
    "            max_beta=0.1, # change for diversity\n",
    "            free_bits=45, # change lower for trade off\n",
    "            dropout_keep_prob=0.3,\n",
    "        )),\n",
    "    note_sequence_augmenter=None,\n",
    "    data_converter=data.GrooveConverter(\n",
    "        split_bars=4, steps_per_quarter=4, quarters_per_bar=4,\n",
    "        max_tensors_per_notesequence=20,\n",
    "        pitch_classes=data.ROLAND_DRUM_PITCH_CLASSES,\n",
    "        inference_pitch_classes=data.REDUCED_DRUM_PITCH_CLASSES),\n",
    "    # change to custom data\n",
    "    train_examples_path='./data/groovae_4bar.tfrecord-00000-of-00001',\n",
    "    eval_examples_path='./data/groove_eval/eval_music.tfrecord'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fdd413d-5eca-4f98-8351-136cf2e9cdb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_note_seq(genre_type):\n",
    "    note_sequence = mm.midi_file_to_note_sequence(os.path.join('./data/groove/', genre_type))\n",
    "    note_sequence = mm.apply_sustain_control_changes(note_sequence)\n",
    "    note_sequence = mm.trim_note_sequence(note_sequence, 0, note_sequence.total_time)\n",
    "    \n",
    "    return note_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c60b1d2-afb6-42a7-8c29-6779773e9035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_4bar_genre(music_genre, temp, outdir_filename):\n",
    "    try:\n",
    "        genre_midi = random.choice(list(info[info['style'] == music_genre]['midi_filename']))\n",
    "        genre_noteseq = generate_note_seq(genre_midi)\n",
    "    except:\n",
    "        print(\"Oops!  The genre we prepared is ['funk', 'rock', 'hiphop'].\")\n",
    "    \n",
    "    generated_sequence = model.sample(n=1, length=16*4, temperature=temp, c_input=genre_noteseq)\n",
    "    note_seq.sequence_proto_to_midi_file(generated_sequence[0], outdir_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3632c63-cdc4-46d9-b57d-a22acfdd1687",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, HierarchicalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 64, 'z_size': 256, 'free_bits': 45, 'max_beta': 0.1, 'beta_rate': 0.0, 'batch_size': 1, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [256, 256], 'enc_rnn_size': [512], 'dropout_keep_prob': 0.3, 'sampling_schedule': 'constant', 'sampling_rate': 0.0, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [512]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Hierarchical Decoder:\n",
      "  input length: 64\n",
      "  level output lengths: [16, 4]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [256, 256]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from ./model_checkpoint_groovae_4bar_hier_beta/model.ckpt-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 20:35:30.659474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46721 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:52:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = TrainedModel(config=CONFIG_MAP['groovae_4bar_hier'],\n",
    "                     batch_size=1, \n",
    "                     checkpoint_dir_or_path='./model_checkpoint_groovae_4bar_hier_beta/model.ckpt-5000') # 체크포인트의 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d6c53f-9792-4164-b7c2-f29a089c17e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "info = pd.read_csv('./data/groove/info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98248b7-2e23-453d-9b2b-2b7942ce1afb",
   "metadata": {},
   "source": [
    "### 비트 생성 후 직접 들어본 결과 temperate가 0.1 일때는 너무 단조로운 패턴이 나와 0.5로 조절했습니다.<br> 또 음악의 장르(['funk', 'rock', 'hiphop'])에 따라 비트를 생성할 수 있게 구성했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2206637c-144e-44a5-aad8-d9cc5fde4c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = 0.5\n",
    "genre_of_music = 'funk'\n",
    "outdir_file = './result/4bar_groovae_hierbeta_5000_drum_4bar_hiphop.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b50d711-a467-4b27-85a8-0281ed606593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_4bar_genre(genre_of_music, temp, outdir_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353862c-dd48-40d8-a588-4e5f5aceefae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98b0fd18-b582-49ff-94a8-0c38555c5b28",
   "metadata": {},
   "source": [
    "# RESULT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b26aaf-0095-44f7-a839-1e8504e47c59",
   "metadata": {},
   "source": [
    "*결과는 Coolsoft의 VirtualMIDISynth를 이용해 직접들으며 판단했습니다. 때문에 매우 주관적인 평가입니다.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd00e63-f72a-4f30-a530-1041a54a5cda",
   "metadata": {},
   "source": [
    "- grooVAE config 구조의 초기 weight의 checkpoint를 load해 비트를 생성한 결과 잘 생성되지 않았습니다.\n",
    "- 그에 비해 5000 steps 까지 학습이 진행된 weights에서는 비교적 생성이 잘 됐다고 느꼈습니다.\n",
    "- 논문에서 제시한 HierarchicalLstmDecoder 구조를 적용한 결과 비교적 초기 weights 에서도 비트를 잘 생성했습니다.\n",
    "    - 평가기준을 잘 알지못해 주관적으로 판단할 수 밖에 없었지만 훨씬 복잡한 비트가 생성됐습니다.\n",
    "- temperate가 0.1 일 때, 매우 단조로운 패턴의 드럼비트가 생성됨을 확인했습니다.\n",
    "- 장르에 따른 결과물들이 듣기에 다른 패턴이 생성된 것처럼 들렸습니다.(주관적인 판단입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c5893-67a1-42df-9ac7-ba370fb5232b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhjang7",
   "language": "python",
   "name": "jhjang7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
